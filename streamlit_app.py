import io
import numpy as np
import pandas as pd
import requests
import streamlit as st
import pydeck as pdk

# =========================
# ê¸°ë³¸ ë°ì´í„° ê²½ë¡œ(ì›í•˜ëŠ” ê²½ë¡œë¡œ ë°”ê¿”ë„ ë¨)
# =========================
DEFAULT_XLSX_PATH = "KPI_-_Repartition_portefeuille-20250716.xlsx"        # ê¸°ë³¸ ì—‘ì…€
DEFAULT_COORDS_CSV_PATH = "rilsa_coords.csv" # ê¸°ë³¸ ì¢Œí‘œ CSV
DEFAULT_SHEET_NAME = None  # Noneì´ë©´ ì²« ì‹œíŠ¸

st.set_page_config(page_title="RILSA map", layout="wide")
st.title("RILSA map")

# =========================
# Tooltip HTML (Nom : Valeur)
# =========================
TOOLTIP_HTML = """
<div style="font-family: ui-sans-serif,system-ui; font-size:12px; line-height:1.25;">
  <div><b>GÃ©rant :</b> {GÃ©rant}</div>
  <div><b>GÃ©rant group :</b> {GÃ©rant group}</div>
  <div><b>Type :</b> {Type}</div>
  <div><b>Adresse :</b> {adresse}</div>
  <div><b>Nombre total d'appartements :</b> {Nombre total d'appartements}</div>
  <div><b>Nombre total d'entreprises :</b> {Nombre total d'entreprises}</div>
  <div><b>PropriÃ©taire :</b> {PropriÃ©taire}</div>
</div>
"""

# =========================
# ë ˆì „ë“œ(í‘œ) ë Œë”ëŸ¬
# =========================
def render_table_legend(keys, cmap, title="LÃ©gende", cols_per_row=4):
    if not keys:
        return
    st.markdown(f"#### {title} (tableau)")
    cols = st.columns(min(cols_per_row, max(1, len(keys))))
    for i, k in enumerate(keys):
        with cols[i % len(cols)]:
            st.markdown(
                f'''
                <div style="display:flex;align-items:center;gap:8px;margin:6px 0;">
                    <span style="width:14px;height:14px;display:inline-block;border-radius:3px;
                                 border:1px solid #0003;background:rgb({cmap[k][0]},{cmap[k][1]},{cmap[k][2]},{cmap[k][3] if len(cmap[k])>3 else 255});"></span>
                    <span style="font-size:13px">{k}</span>
                </div>
                ''',
                unsafe_allow_html=True
            )

# =========================
# ë©€í‹°ì…€ë ‰íŠ¸ ë‚´ë¶€ì— "Tout" ì˜µì…˜ ë‚´ì¥
# =========================
def multiselect_with_select_all(label: str, options: list, key: str):
    ALL = "Tout"
    opts = [ALL] + options
    selected_real = st.session_state.get(key, options)  # ì´ˆê¸°ì—” ì „ì²´ ì„ íƒ
    default_widget = [ALL] + options if set(selected_real) == set(options) else selected_real
    sel = st.multiselect(label, options=opts, default=default_widget, key=f"{key}__widget")
    chosen = options if ALL in sel else [x for x in sel if x != ALL]
    st.session_state[key] = chosen
    return chosen

# =========================
# ìƒ‰ìƒ íŒ”ë ˆíŠ¸ + ìƒ‰ìƒ ì ìš©(ë°˜íˆ¬ëª…)
# =========================
PALETTE = [
    [230, 25, 75], [60, 180, 75], [0, 130, 200], [245, 130, 48], [145, 30, 180],
    [70, 240, 240], [240, 50, 230], [210, 245, 60], [250, 190, 190], [170, 110, 40],
]

def assign_colors(df_points, color_key, palette=PALETTE, alpha=120):
    if (not color_key) or (color_key not in df_points.columns):
        df_points["color"] = [[0, 0, 200, alpha]] * len(df_points)
        return [], {}
    keys = sorted(df_points[color_key].astype(str).unique().tolist())
    cmap = {k: palette[i % len(palette)] + [alpha] for i, k in enumerate(keys)}
    df_points["color"] = df_points[color_key].astype(str).map(cmap)
    return keys, cmap

# =========================
# ë¶„ë¥˜/ê·¸ë£¹ ìœ í‹¸
# =========================
def classify_type_from_ref(ref):
    if pd.isna(ref):
        return "Inconnu"
    ref = int(ref)
    if 100000 <= ref <= 499000:
        return "Immeuble"
    elif 500000 <= ref <= 599000:
        return "Lot isolÃ©"
    elif 800000 <= ref <= 950000:
        return "PPE"
    else:
        return "Autre"

def compute_gerant_group(name):
    if pd.isna(name):
        return None
    n = str(name).strip()
    if n in {"NIGGLI Lucy", "BENISTANT Audrey"}:
        return "Nyon"
    if n in {"CURCHOD Merry", "DE PREUX Joanna"}:
        return "Montreux"
    return n

def safe_mean(series, default):
    try:
        v = float(series.mean())
        return v if not np.isnan(v) else default
    except:
        return default

# =========================
# Google Geocoding
# =========================
def gmaps_geocode_one(address: str, key: str):
    url = "https://maps.googleapis.com/maps/api/geocode/json"
    params = {"address": address, "key": key, "region": "ch", "language": "fr"}
    try:
        r = requests.get(url, params=params, timeout=10)
        data = r.json()
        if data.get("status") == "OK" and data.get("results"):
            loc = data["results"][0]["geometry"]["location"]
            return (loc["lat"], loc["lng"])
        else:
            return (None, None)
    except Exception:
        return (None, None)

@st.cache_data(show_spinner=False)
def gmaps_geocode_batch(addresses: tuple, key: str):
    out = {}
    progress = st.progress(0)
    total = len(addresses)
    for i, addr in enumerate(addresses, start=1):
        out[addr] = gmaps_geocode_one(addr, key)
        progress.progress(i/total)
    return out

# =========================
# ì—…ë¡œë“œ / ê¸°ë³¸ ë°ì´í„° ì„ íƒ
# =========================
uploaded_file = st.file_uploader("TÃ©lÃ©versez un fichier Excel (.xlsx)", type=["xlsx"])
use_default = st.sidebar.toggle(
    "Utiliser les donnÃ©es par dÃ©faut (Excel + CSV lat/lon)",
    value=(uploaded_file is None)
)

# =========================
# ë°ì´í„° ë¡œë”© (ì—…ë¡œë“œ ë˜ëŠ” ê¸°ë³¸)
# =========================
df = None
source_desc = ""
try:
    if not use_default and uploaded_file is not None:
        xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
        sheet = st.selectbox("Choisissez une feuille", xls.sheet_names, index=0)
        df = pd.read_excel(xls, sheet_name=sheet, engine="openpyxl", skiprows=4)
        source_desc = f"Fichier chargÃ© : {uploaded_file.name} / Feuille : {sheet}"
    else:
        xls = pd.ExcelFile(DEFAULT_XLSX_PATH, engine="openpyxl")
        sheet_names = xls.sheet_names
        sheet = DEFAULT_SHEET_NAME if (DEFAULT_SHEET_NAME in sheet_names) else sheet_names[0]
        df = pd.read_excel(xls, sheet_name=sheet, engine="openpyxl", skiprows=4)
        source_desc = f"DonnÃ©es par dÃ©faut : {DEFAULT_XLSX_PATH} / Feuille : {sheet}"
except Exception as e:
    st.error(f"Impossible de charger le fichier Excel: {e}")
    st.stop()

# =========================
# ì „ì²˜ë¦¬
# =========================
# 1) Support User ì œê±°
if "GÃ©rant" in df.columns:
    df["GÃ©rant"] = df["GÃ©rant"].astype(str)
    df = df[df["GÃ©rant"].str.strip() != "REM4you (Support User)"].reset_index(drop=True)

# 2) RÃ©fÃ©rence â†’ Type
if "RÃ©fÃ©rence" in df.columns:
    df["RÃ©fÃ©rence"] = pd.to_numeric(df["RÃ©fÃ©rence"].astype(str).str.replace(r"[^\d]", "", regex=True), errors="coerce")
    df["Type"] = df["RÃ©fÃ©rence"].apply(classify_type_from_ref)
else:
    st.warning("âš ï¸ Colonne 'RÃ©fÃ©rence' absente : 'Type' ne sera pas crÃ©Ã©.")

# 3) GÃ©rant group
if "GÃ©rant" in df.columns:
    df["GÃ©rant group"] = df["GÃ©rant"].apply(compute_gerant_group)
else:
    st.warning("âš ï¸ Colonne 'GÃ©rant' introuvable â€” impossible de crÃ©er 'GÃ©rant group'.")

st.success(source_desc)

# =========================
# í•„í„°
# =========================
st.sidebar.header("Filtres")
with st.sidebar:
    if "GÃ©rant" in df.columns:
        gerant_opts = sorted(df["GÃ©rant"].dropna().astype(str).unique().tolist())
        gerant_sel = multiselect_with_select_all("GÃ©rant", gerant_opts, key="gerant")
    else:
        gerant_sel = None
        st.info("Colonne 'GÃ©rant' introuvable â€” filtre dÃ©sactivÃ©.")

    if "Type" in df.columns:
        type_opts = sorted(df["Type"].dropna().astype(str).unique().tolist())
        type_sel = multiselect_with_select_all("Type", type_opts, key="type")
    else:
        type_sel = None
        st.info("Colonne 'Type' introuvable â€” filtre dÃ©sactivÃ©.")

# í•„í„° ì ìš©
df_filtered = df.copy()
if gerant_sel is not None:
    df_filtered = df_filtered[df_filtered["GÃ©rant"].astype(str).isin(gerant_sel)]
if type_sel is not None and "Type" in df_filtered.columns:
    df_filtered = df_filtered[df_filtered["Type"].astype(str).isin(type_sel)]

#st.subheader("Tableau filtrÃ©")
#st.dataframe(df_filtered, use_container_width=True)

# =========================
# ì£¼ì†Œ ìƒì„±
# =========================
required_cols = ["DÃ©signation", "NPA", "Lieu", "Canton"]
missing = [c for c in required_cols if c not in df_filtered.columns]
if missing:
    st.error(f"Colonnes manquantes pour construire l'adresse : {', '.join(missing)}")
    st.stop()
if df_filtered.empty:
    st.info("Aucune ligne aprÃ¨s filtrage.")
    st.stop()

df_filtered["adresse"] = (
    df_filtered["DÃ©signation"].astype(str).str.strip() + ", " +
    df_filtered["NPA"].astype(str).str.strip() + " " +
    df_filtered["Lieu"].astype(str).str.strip() + ", " +
    df_filtered["Canton"].astype(str).str.strip() + ", Suisse"
)

# ì¢Œí‘œ ì»¬ëŸ¼ ë³´ì¥
if "latitude" not in df_filtered.columns:
    df_filtered["latitude"] = np.nan
if "longitude" not in df_filtered.columns:
    df_filtered["longitude"] = np.nan

# =========================
# ê¸°ë³¸ ì¢Œí‘œ CSV ìë™ ë³‘í•©
# =========================
try:
    default_coords = pd.read_csv(DEFAULT_COORDS_CSV_PATH)
    merged = False
    if {"adresse","latitude","longitude"}.issubset(default_coords.columns):
        df_filtered = df_filtered.merge(
            default_coords[["adresse","latitude","longitude"]],
            on="adresse", how="left", suffixes=("", "_def")
        )
        if "latitude_def" in df_filtered.columns and "longitude_def" in df_filtered.columns:
            df_filtered["latitude"]  = df_filtered["latitude"].fillna(df_filtered["latitude_def"])
            df_filtered["longitude"] = df_filtered["longitude"].fillna(df_filtered["longitude_def"])
            df_filtered.drop(columns=["latitude_def","longitude_def"], inplace=True)
        merged = True
    if (not merged) and {"RÃ©fÃ©rence","latitude","longitude"}.issubset(default_coords.columns) and "RÃ©fÃ©rence" in df_filtered.columns:
        df_filtered = df_filtered.merge(
            default_coords[["RÃ©fÃ©rence","latitude","longitude"]],
            on="RÃ©fÃ©rence", how="left", suffixes=("", "_def")
        )
        if "latitude_def" in df_filtered.columns and "longitude_def" in df_filtered.columns:
            df_filtered["latitude"]  = df_filtered["latitude"].fillna(df_filtered["latitude_def"])
            df_filtered["longitude"] = df_filtered["longitude"].fillna(df_filtered["longitude_def"])
            df_filtered.drop(columns=["latitude_def","longitude_def"], inplace=True)
        merged = True
    if merged:
        st.success("CoordonnÃ©es par dÃ©faut appliquÃ©es.")
except FileNotFoundError:
    st.warning(f"CSV lat/lon par dÃ©faut introuvable: {DEFAULT_COORDS_CSV_PATH}")
except Exception as e:
    st.warning(f"Impossible de fusionner le CSV par dÃ©faut: {e}")

# =========================
# (ì˜µì…˜) ì¢Œí‘œ CSV ì—…ë¡œë“œë¡œ ì¶”ê°€ ì¬ì‚¬ìš©
# =========================
st.sidebar.markdown("### Recharger des coordonnÃ©es (CSV)")
coords_file = st.sidebar.file_uploader(
    "CSV avec 'adresse,latitude,longitude' ou 'RÃ©fÃ©rence,latitude,longitude'",
    type=["csv"], key="coords_csv"
)
if coords_file is not None:
    try:
        coords_df = pd.read_csv(coords_file)
        merged = False
        if {"adresse","latitude","longitude"}.issubset(coords_df.columns):
            df_filtered = df_filtered.merge(
                coords_df[["adresse","latitude","longitude"]],
                on="adresse", how="left", suffixes=("", "_cache")
            )
            if "latitude_cache" in df_filtered.columns and "longitude_cache" in df_filtered.columns:
                df_filtered["latitude"]  = df_filtered["latitude"].fillna(df_filtered["latitude_cache"])
                df_filtered["longitude"] = df_filtered["longitude"].fillna(df_filtered["longitude_cache"])
                df_filtered.drop(columns=["latitude_cache","longitude_cache"], inplace=True)
            merged = True
        if (not merged) and {"RÃ©fÃ©rence","latitude","longitude"}.issubset(coords_df.columns) and "RÃ©fÃ©rence" in df_filtered.columns:
            df_filtered = df_filtered.merge(
                coords_df[["RÃ©fÃ©rence","latitude","longitude"]],
                on="RÃ©fÃ©rence", how="left", suffixes=("", "_cache")
            )
            if "latitude_cache" in df_filtered.columns and "longitude_cache" in df_filtered.columns:
                df_filtered["latitude"]  = df_filtered["latitude"].fillna(df_filtered["latitude_cache"])
                df_filtered["longitude"] = df_filtered["longitude"].fillna(df_filtered["longitude_cache"])
                df_filtered.drop(columns=["latitude_cache","longitude_cache"], inplace=True)
            merged = True
        if merged:
            st.success("CoordonnÃ©es rechargÃ©es depuis le CSV (upload).")
    except Exception as e:
        st.sidebar.error(f"Erreur CSV coords: {e}")

# =========================
# Google ì§€ì˜¤ì½”ë”© (ê²°ì¸¡ë§Œ)
# =========================
st.subheader("GÃ©ocodage Google Maps (complÃ©ter les manquants)")
limit = st.slider("Limiter le nombre d'adresses Ã  gÃ©ocoder maintenant", 10, 1000, 200, 10)

need_geo = df_filtered[
    df_filtered["adresse"].notna() &
    (
        ("latitude" not in df_filtered.columns) |
        ("longitude" not in df_filtered.columns) |
        df_filtered["latitude"].isna() | df_filtered["longitude"].isna()
    )
].copy()

to_geocode = need_geo["adresse"].dropna().unique().tolist()[:limit]

col1, col2 = st.columns(2)
with col1:
    st.write(f"Adresses sans coordonnÃ©es (sÃ©lection) : **{len(to_geocode)}**")
with col2:
    start_geo = st.button("ğŸš€ Lancer le gÃ©ocodage Google")

if start_geo:
    if not api_key:
        st.error("Veuillez saisir votre **Google Maps API Key**.")
        st.stop()
    mapping = gmaps_geocode_batch(tuple(to_geocode), api_key)
    mask_map = df_filtered["adresse"].isin(mapping.keys())
    df_filtered.loc[mask_map, "latitude"]  = df_filtered.loc[mask_map, "adresse"].map(lambda a: mapping.get(a,(None,None))[0])
    df_filtered.loc[mask_map, "longitude"] = df_filtered.loc[mask_map, "adresse"].map(lambda a: mapping.get(a,(None,None))[1])
    st.success("GÃ©ocodage Google terminÃ© pour le lot courant.")

# =========================
# ìµœì¢… ì§€ë„ + ë ˆì „ë“œ + CSV ë‹¤ìš´ë¡œë“œ
# =========================
plotted_final = df_filtered.dropna(subset=["latitude","longitude"]).copy()
st.markdown("### Carte (mise Ã  jour)")
if not plotted_final.empty:
    color_key = "GÃ©rant group" if "GÃ©rant group" in plotted_final.columns else ("GÃ©rant" if "GÃ©rant" in plotted_final.columns else None)
    keys_final, cmap_final = assign_colors(plotted_final, color_key)

    # íˆ´íŒ í•„ë“œ ë³´ì •
    for c in ["GÃ©rant","GÃ©rant group","Type","adresse","Nombre total d'appartements","Nombre total d'entreprises","PropriÃ©taire"]:
        if c not in plotted_final.columns:
            plotted_final[c] = ""

    view_state2 = pdk.ViewState(
        latitude=safe_mean(plotted_final["latitude"], 46.8182),
        longitude=safe_mean(plotted_final["longitude"], 8.2275),
        zoom=9
    )
    layer2 = pdk.Layer(
        "ScatterplotLayer",
        data=plotted_final,
        get_position='[longitude, latitude]',
        get_fill_color="color",
        get_radius=200,      # ì  í¬ê¸° â€” í•„ìš”ì‹œ ì¡°ì ˆ
        pickable=True,
    )
    st.pydeck_chart(pdk.Deck(
        layers=[layer2],
        initial_view_state=view_state2,
        tooltip={"html": TOOLTIP_HTML, "style": {"backgroundColor":"rgba(255,255,255,0.95)", "color":"black"}}
    ))

    legend_title_final = color_key if color_key else "CatÃ©gorie"
    render_table_legend(keys_final, cmap_final, f"LÃ©gende â€” {legend_title_final}", cols_per_row=4)

    # ì¢Œí‘œ CSV ë‹¤ìš´ë¡œë“œ
    st.markdown("### TÃ©lÃ©charger les coordonnÃ©es")
    save_cols = [c for c in [
        "RÃ©fÃ©rence","GÃ©rant","GÃ©rant group","Type",
        "DÃ©signation","NPA","Lieu","Canton",
        "adresse","latitude","longitude",
        "Nombre total d'appartements","Nombre total d'entreprises","PropriÃ©taire"
    ] if c in plotted_final.columns]
    export_df = plotted_final[save_cols].copy()
    st.download_button(
        label="â¬‡ï¸ TÃ©lÃ©charger CSV (lat/lon inclus)",
        data=export_df.to_csv(index=False).encode("utf-8"),
        file_name="rilsa_coords.csv",
        mime="text/csv"
    )
else:
    st.info("Aucun point avec coordonnÃ©es pour lâ€™instant. Lancez le gÃ©ocodage Google ou vÃ©rifiez vos filtres.")

# =========================
# API Key
# =========================
api_key = st.secrets.get("GOOGLE_MAPS_API_KEY", None)
if not api_key:
    api_key = st.text_input("Entrez votre Google Maps API Key", type="password")
