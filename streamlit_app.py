import streamlit as st
import pandas as pd
import pydeck as pdk

# G√©ocodage
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter

st.set_page_config(page_title="RILSA map", layout="wide")
st.title("RILSA map")

uploaded_file = st.file_uploader("T√©l√©versez un fichier Excel (.xlsx)", type=["xlsx"])

df = None

if uploaded_file is not None:
    try:
        # Charger Excel
        xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
        sheet = st.selectbox("Choisissez une feuille", xls.sheet_names, index=0)

        df = pd.read_excel(xls, sheet_name=sheet, engine="openpyxl", skiprows=4)

        # ‚úÖ Supprimer les lignes avec G√©rant = "REM4you (Support User)"
        if "G√©rant" in df.columns:
            df = df[df["G√©rant"] != "REM4you (Support User) "].reset_index(drop=True)
            mask = pd.Series(True, index=df.index)   # dfÏôÄ Í∞ôÏùÄ Ïù∏Îç±Ïä§Î°ú ÏÉùÏÑ±

        # Conversion de "R√©f√©rence" et ajout "Type"
        if "R√©f√©rence" in df.columns:
            df["R√©f√©rence"] = pd.to_numeric(
                df["R√©f√©rence"].astype(str).str.replace(r"[^\d]", "", regex=True),
                errors="coerce"
            )

            def classify_type(ref):
                if pd.isna(ref):
                    return "Inconnu"
                ref = int(ref)
                if 100000 <= ref <= 499000:
                    return "Immeuble"
                elif 500000 <= ref <= 599000:
                    return "Lot"
                elif 800000 <= ref <= 950000:
                    return "PPE"
                else:
                    return "Autre"

            df["Type"] = df["R√©f√©rence"].apply(classify_type)

        # ‚úÖ Nouveau: cr√©er la colonne "G√©rant group"
        def compute_gerant_group(name):
            if pd.isna(name):
                return None
            n = str(name).strip()
            if n in {"NIGGLI Lucy", "BENISTANT Audrey"}:
                return "Nyon"
            if n in {"CURCHOD Merry", "DE PREUX Joanna"}:
                return "Montreux"
            return n  # les autres gardent la valeur d'origine

        if "G√©rant" in df.columns:
            df["G√©rant group"] = df["G√©rant"].apply(compute_gerant_group)
        else:
            st.warning("‚ö†Ô∏è Colonne 'G√©rant' introuvable ‚Äî impossible de cr√©er 'G√©rant group'.")

        st.success(f"Fichier charg√© : {uploaded_file.name} / Feuille : {sheet}")

        # -------------------- Filtres --------------------
        st.sidebar.header("Filtres")

        # On garde les filtres existants
        gerant_selected = None
        if "G√©rant" in df.columns:
            gerant_options = sorted(df["G√©rant"].dropna().unique().tolist())
            gerant_selected = st.sidebar.multiselect("G√©rant", options=gerant_options, default=gerant_options)

        type_selected = None
        if "Type" in df.columns:
            type_options = sorted(df["Type"].dropna().unique().tolist())
            type_selected = st.sidebar.multiselect("Type", options=type_options, default=type_options)

        mask = pd.Series([True] * len(df))
        if gerant_selected is not None:
            mask &= df["G√©rant"].isin(gerant_selected)
        if type_selected is not None:
            mask &= df["Type"].isin(type_selected)
        
        df_filtered = df[mask].copy()

        st.subheader("Tableau filtr√©")
        st.dataframe(df_filtered, use_container_width=True)

        # -------------------- Adresse & G√©ocodage (optimis√©) --------------------
        required_cols = ["D√©signation", "NPA", "Lieu", "Canton"]
        missing = [c for c in required_cols if c not in df_filtered.columns]
        if missing or df_filtered.empty:
            if missing:
                st.error(f"Colonnes manquantes pour construire l'adresse : {', '.join(missing)}")
            else:
                st.info("Aucune ligne apr√®s filtrage.")
        else:
            df_filtered["adresse"] = (
                df_filtered["D√©signation"].astype(str).str.strip() + ", " +
                df_filtered["NPA"].astype(str).str.strip() + " " +
                df_filtered["Lieu"].astype(str).str.strip() + ", " +
                df_filtered["Canton"].astype(str).str.strip() + ", Suisse"
            )

            # 1) Î®ºÏ†Ä Ï¢åÌëú ÏûàÎäî ÌñâÎßå Ï¶âÏãú ÏßÄÎèÑ ÌëúÏãú
            has_latlon = ("latitude" in df_filtered.columns) and ("longitude" in df_filtered.columns)
            plotted_now = df_filtered.dropna(subset=["latitude","longitude"]).copy() if has_latlon else pd.DataFrame()

            # Ïª¨Îü¨ Îßµ Ï§ÄÎπÑ (G√©rant group Ïö∞ÏÑ†)
            palette = [
                [230,25,75],[60,180,75],[0,130,200],[245,130,48],[145,30,180],
                [70,240,240],[240,50,230],[210,245,60],[250,190,190],[170,110,40]
            ]
            def apply_colors(df_points, key):
                if key in df_points.columns:
                    keys = sorted(df_points[key].astype(str).unique().tolist())
                    cmap = {k: palette[i % len(palette)] for i,k in enumerate(keys)}
                    df_points["color"] = df_points[key].astype(str).map(cmap)
                    return keys, cmap
                df_points["color"] = [[0,0,200]] * len(df_points)
                return [], {}

            color_key = "G√©rant group" if "G√©rant group" in df_filtered.columns else ("G√©rant" if "G√©rant" in df_filtered.columns else None)
            if not plotted_now.empty:
                keys, cmap = apply_colors(plotted_now, color_key) if color_key else ([], {})
                view_state = pdk.ViewState(
                    latitude=float(plotted_now["latitude"].mean()) if not plotted_now["latitude"].empty else 46.8182,
                    longitude=float(plotted_now["longitude"].mean()) if not plotted_now["longitude"].empty else 8.2275,
                    zoom=9
                )
                layer = pdk.Layer(
                    "ScatterplotLayer",
                    data=plotted_now[["longitude","latitude","adresse","Type","G√©rant","G√©rant group","color"] if "G√©rant group" in df_filtered.columns else ["longitude","latitude","adresse","Type","G√©rant","color"]],
                    get_position='[longitude, latitude]',
                    get_fill_color="color",
                    get_radius=60,
                    pickable=True,
                )
                st.markdown("### Carte (coordonn√©es existantes)")
                st.pydeck_chart(pdk.Deck(layers=[layer], initial_view_state=view_state,
                                        tooltip={"text": "{G√©rant group}\n{G√©rant}\n{Type}\n{adresse}"}))

            # 2) Í≤∞Ï∏° Ï¢åÌëúÎßå Î≤ÑÌäºÏúºÎ°ú ÏßÄÏò§ÏΩîÎî© (Nominatim ÎäêÎ¶º ‚Üí Î∞∞Ïπò Ï†úÌïú)
            #    Ï∫êÏãú + ÌååÏùº Ï†ÄÏû•(ÏòÅÍµ¨)Î°ú Îã§Ïùå Ïã§Ìñâ Í∞ÄÏÜç
            geolocator = Nominatim(user_agent="rilsa_map_app", timeout=10)
            rate_limited_geocode = RateLimiter(geolocator.geocode, min_delay_seconds=3, max_retries=2, swallow_exceptions=True)

            import hashlib, json, os, pathlib
            CACHE_DIR = pathlib.Path("./.geo_cache")
            CACHE_DIR.mkdir(exist_ok=True)
            file_sig = hashlib.md5(f"{uploaded_file.name}|{sheet}".encode("utf-8")).hexdigest()
            cache_path = CACHE_DIR / f"geocode_cache_{file_sig}.json"

            # ÎîîÏä§ÌÅ¨ Ï∫êÏãú Î°úÎìú
            if cache_path.exists():
                with open(cache_path, "r", encoding="utf-8") as f:
                    disk_cache = json.load(f)
            else:
                disk_cache = {}

            # Ïù¥ÎØ∏ Ï∫êÏãú/Ï¢åÌëú ÏûàÎäî Ìñâ Ï†úÏô∏ÌïòÍ≥† Ï£ºÏÜå Î™©Î°ù Íµ¨ÏÑ±
            need_geo_df = df_filtered.copy()
            if has_latlon:
                need_geo_df = need_geo_df[need_geo_df["latitude"].isna() | need_geo_df["longitude"].isna()].copy()
            to_geocode_all = [a for a in need_geo_df["adresse"].dropna().unique().tolist() if a not in disk_cache]

            st.subheader("G√©ocodage des adresses manquantes (Nominatim)")
            limit = st.slider("Limite de g√©ocodage pour cette ex√©cution", 10, 500, 100, 10)
            to_geocode = to_geocode_all[:limit]

            col1, col2 = st.columns(2)
            with col1:
                st.write(f"Adresses √† g√©ocoder (hors cache) : **{len(to_geocode_all)}**")
            with col2:
                start_geo = st.button("üöÄ Lancer le g√©ocodage (lot limit√©)")

            @st.cache_data(show_spinner=False)
            def geocode_batch(addresses: tuple):
                # cache_dataÎäî Î©îÎ™®Î¶¨ Ï∫êÏãú(ÏÑ∏ÏÖòÏö©). ÎîîÏä§ÌÅ¨ Ï∫êÏãúÎäî Î≥ÑÎèÑÎ°ú Í¥ÄÎ¶¨.
                out = {}
                progress = st.progress(0)
                total = len(addresses)
                for i, addr in enumerate(addresses, start=1):
                    loc = rate_limited_geocode(addr)
                    if loc:
                        out[addr] = (loc.latitude, loc.longitude)
                    else:
                        out[addr] = (None, None)
                    progress.progress(i/total)
                return out

            if start_geo and to_geocode:
                new_mapping = geocode_batch(tuple(to_geocode))
                # ÎîîÏä§ÌÅ¨ Ï∫êÏãú Î≥ëÌï©/Ï†ÄÏû•
                disk_cache.update({k: v for k, v in new_mapping.items() if k})
                with open(cache_path, "w", encoding="utf-8") as f:
                    json.dump(disk_cache, f, ensure_ascii=False)

            # Ï∫êÏãú(Î©îÎ™®Î¶¨+ÎîîÏä§ÌÅ¨) Î™®ÏïÑÏÑú Ï¢åÌëú Ï£ºÏûÖ
            def get_coords(addr):
                if addr in disk_cache:
                    return disk_cache[addr]
                return (None, None)

            df_filtered["latitude"]  = df_filtered.get("latitude")
            df_filtered["longitude"] = df_filtered.get("longitude")
            coords_series = df_filtered["adresse"].map(get_coords)
            df_filtered.loc[df_filtered["latitude"].isna(),  "latitude"]  = coords_series.map(lambda x: x[0])
            df_filtered.loc[df_filtered["longitude"].isna(), "longitude"] = coords_series.map(lambda x: x[1])

            plotted_final = df_filtered.dropna(subset=["latitude","longitude"]).copy()

            st.markdown("### Carte (mise √† jour apr√®s g√©ocodage)")
            if not plotted_final.empty:
                keys, cmap = apply_colors(plotted_final, color_key) if color_key else ([], {})
                view_state2 = pdk.ViewState(
                    latitude=float(plotted_final["latitude"].mean()),
                    longitude=float(plotted_final["longitude"].mean()),
                    zoom=9
                )
                layer2 = pdk.Layer(
                    "ScatterplotLayer",
                    data=plotted_final[["longitude","latitude","adresse","Type","G√©rant","G√©rant group","color"] if "G√©rant group" in df_filtered.columns else ["longitude","latitude","adresse","Type","G√©rant","color"]],
                    get_position='[longitude, latitude]',
                    get_fill_color="color",
                    get_radius=60,
                    pickable=True,
                )
                st.pydeck_chart(pdk.Deck(layers=[layer2], initial_view_state=view_state2,
                                        tooltip={"text": "{G√©rant group}\n{G√©rant}\n{Type}\n{adresse}"}))
            else:
                st.info("Coordonn√©es encore insuffisantes. Îã§Ïùå Î∞∞ÏπòÎ°ú Ï∂îÍ∞Ä ÏßÄÏò§ÏΩîÎî© ÌïòÏÑ∏Ïöî.")
